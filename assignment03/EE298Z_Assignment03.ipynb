{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EE298Z_Assignment03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WnAph025ctBbiHSibVFogHQZoSiyjlfA",
      "authorship_tag": "ABX9TyNO3L5vC2GffkIzQ0bKnENI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soymarwin/ee298z/blob/main/EE298Z_Assignment03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZfY0uzDh1qG"
      },
      "source": [
        "# **EE298Z Deep Learning**\r\n",
        "## **Assignment 03**\r\n",
        "\r\n",
        "Performed by Marwin B. Alejo 2020-20221\r\n",
        "\r\n",
        "*Task: Implement AdaIN Style Transfer on SVHN (source) and MNIST (target) dataset.*\r\n",
        "\r\n",
        "Resources and Tools:\r\n",
        "1. Google Colab in GPU Mode\r\n",
        "2. [GitHub](https://github.com/soymarwin/ee298z/blob/main/assignment03/)\r\n",
        "3. PyTorch\r\n",
        "4. Raw MNIST and SVHN Images. *(Pre-defined PyTorch datasets may also be used but requires different pre-processing.)*\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmETMlSjGMP4"
      },
      "source": [
        "**Execution training time.**\r\n",
        "\r\n",
        "Disclaimer: Since Google Colab is the chosen platform in this assignment execution, training performance(speed) depends on your node of choice, plan, and internet connectivity. Better use Google Colab Pro or GCC node for faster compute time and longer training time node allocation.\r\n",
        "\r\n",
        "1. ~1 hour in an ideal network speed and weather condition for 500-1000 iterations.<br>\r\n",
        "2. ~2 hours for 10000 iterations. <br>\r\n",
        "3. ~4 hours for 20000 iterations. <br>\r\n",
        "3. ~6hours for 50000 iter and ~12 hours for 100000 iter. <br>\r\n",
        "\r\n",
        "*Time spent for framework configuration trials and model composition is 10 days.*\r\n",
        "\r\n",
        "**Disclaimer: It is not possible to perform a ~50000+ and iteration training due to the limits with Google Colab GPU node.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYZqbA85ER2_"
      },
      "source": [
        "Overall, AdaIN Style Transfer, unlike SGAN and CycleGAN, is more on artistic style transfer than value-based style transfer. This is seen with the outputs below and with the SGAN/CGAN as shown [here](https://github.com/yunjey/mnist-svhn-transfer) fore benchmarking. Artistic means that the style of the prvious is transfer to the latter (target) while in SGAN and CGAN, the vaues are being complete similar to the former (source style). The train.py and test.oy are both modified as such they may accept both the raw style and target images regardless of their shape. Furthermore, the output is of the shape (3ch, 32px, 32px). \r\n",
        "\r\n",
        "Theoretically, the longer the model was trained, the better the style-transfer output would be. However, due to compute resource constraint and time limit allocation for Google Colab GPU connection, only up to 20000 iter was performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBsgBzttiWiW"
      },
      "source": [
        "1. Connect Google Colab to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_junthaj4uQb",
        "outputId": "d440404d-213f-4550-a0b1-15638d4fe6b3"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "path = \"/content/drive/MyDrive/Colab/EE298Z_Assignment03/data/\"\n",
        "sys.path.append(path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffPjaXGMsOAX"
      },
      "source": [
        "2. Get MNIST and SVHN Datasets and directory preparation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8IXMBSWwVNU"
      },
      "source": [
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krxMr8A-wZAF"
      },
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/Colab/EE298Z_Assignment03/data/mnist_png.tar.gz\" -C \"/content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao7KFFwTvodg"
      },
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ3CmPZcwwOU"
      },
      "source": [
        "dir_name = \"/content/drive/MyDrive/Colab/EE298Z_Assignment03/data/style/\"\r\n",
        "print(\"Loading matlab data of SVHN\")\r\n",
        "mat = sio.loadmat(\"/content/drive/MyDrive/Colab/EE298Z_Assignment03/data/train.mat\")\r\n",
        "data = mat['X']\r\n",
        "for i in range(data.shape[3]):\r\n",
        "  plt.figure()\r\n",
        "  if not os.path.isfile(os.path.join(dir_name, \"%05d.png\" % i)):\r\n",
        "    plt.imsave(os.path.join(dir_name, \"%05d.png\" % i), data[..., i])\r\n",
        "  plt.close()\r\n",
        "print(\"Program done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FyPQtf85KcB"
      },
      "source": [
        "**Sample Target**\r\n",
        "\r\n",
        "![sample_target.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAuUlEQVR4nNWRIRCCQBBFL0OFapaK2WzGqpnqWDFKtjJWjUKmQr7qWTGKFeP9w0Mju8Xm7syVN7v/7z8h/rH8bW1gO18SsIT+djcdQ9m3ZSzlEyYbwygL7RvUGhtG2FUGkmE7ZTUjms0Gt5lPQ+dq3T6ahDpm2Nt8bl3Q1Av3VrdiPNmoTgYxCyX0nIMpzIqbO0C3E5oFNxjFzJ076NwhgFsU6HGn00uH37x49MojXpIJToh1lXDoh3oDvo9hYu9pCVoAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnbyAKov5aKh"
      },
      "source": [
        "**Sample Style**\r\n",
        "\r\n",
        "![sample_style.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoSKrpm5v4DD"
      },
      "source": [
        "3. Training with 500 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M0WvTzJy3GM"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/train.py --content-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/ --style-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/ --max-iter 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJbCWmCnzAbX"
      },
      "source": [
        "4. Test with weights from 500 iterations on single image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8MP58ieE5Cp",
        "outputId": "80269a97-1598-45fc-f5cc-a537c9a81a58"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/test.py --model /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/experiments/iter_500.pth --content /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/9999.png --style /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/09999.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/1] Content: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/9999.png, Style: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/09999.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Qkg0dQ0z_G"
      },
      "source": [
        "**Styled Image in 500 iter**\r\n",
        "\r\n",
        "![9999_stylized_09999_iter500.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WENoAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTXQ-i5HzVNO"
      },
      "source": [
        "5. Training with 10000 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0qn3PIm5XFL",
        "outputId": "20038cbc-1238-4cf7-d536-2bd94156b8d2"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/train.py --content-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/ --style-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/ --max-iter 10000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-08 17:31:59.753333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "100% 10000/10000 [52:31<00:00,  3.17it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmsBWv3RyhxR"
      },
      "source": [
        "6. Testing with single image and generated weight from 10000 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dUEfefOggoU",
        "outputId": "8476dffa-f3a6-4234-dcff-9bcff3acc20f"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/test.py --model /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/experiments/iter_10000.pth --content /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/25.png --style /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/00003.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/1] Content: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/25.png, Style: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/00003.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN3HnN3r3a-T"
      },
      "source": [
        "**Styled Image in 10000 iter**\r\n",
        "\r\n",
        "![30_stylized_00003_iter10000.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzG_WMfn6tkh"
      },
      "source": [
        "7. Training with 20000 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwpcuOcnnlNt",
        "outputId": "cc5b5124-fa7c-491b-86e3-c12ac6820455"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/train.py --content-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/ --style-dir /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/ --max-iter 20000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:40<00:00, 14.3MB/s]\n",
            "2020-12-09 02:56:50.605376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "  1% 131/20000 [03:46<10:15:14,  1.86s/it]\n",
            "  3% 680/20000 [19:42<7:36:20,  1.42s/it] \n",
            "\n",
            "100% 20000/20000 [3:32:07<00:00,  1.57it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d506kn4W6kRh"
      },
      "source": [
        "8. Testing with single image using 20000 iterations weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcyUc8voaeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1fc453-2740-4cfd-ffb4-6af72bc22829"
      },
      "source": [
        "!python /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/test.py --model /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/experiments/iter_20000.pth --content /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/30.png --style /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/00003.png"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/1] Content: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/contents/30.png, Style: /content/drive/MyDrive/Colab/EE298Z_Assignment03/data/styles/00003.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09UEgUcn6FXk"
      },
      "source": [
        "**Styled Image in 20000 iter**\r\n",
        "\r\n",
        "![30_stylized_00003_iter20000.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfv4KrbqpAYi"
      },
      "source": [
        "## **TODO (for future explorers)**\r\n",
        "\r\n",
        "1. Unified preprocessing (environment preparation) on Google Colab.\r\n",
        "2. Training using [extra set of SVHN cropped](http://ufldl.stanford.edu/housenumbers/extra_32x32.mat). \r\n",
        "3. Training and testing using PyTorch's in-house [MNIST and SVHN datasets](https://pytorch.org/docs/stable/torchvision/datasets.html).\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xsbk8ydo7Vt"
      },
      "source": [
        "## **References**\r\n",
        "\r\n",
        "1. [Original paper of Huang and Belongie](https://arxiv.org/abs/1703.06868)\r\n",
        "2. [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\r\n",
        "3. [AdaIN TF-K implemetation](https://github.com/ftokarev/tf-adain)\r\n",
        "4. [AdaIN PyTorch implementation](https://github.com/naoto0804/pytorch-AdaIN)\r\n",
        "5. [Basis: AdaIN PyTorch implementation](https://github.com/kukosmos/adain-pytorch-2019)"
      ]
    }
  ]
}